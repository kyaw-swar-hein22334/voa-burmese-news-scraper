{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d662398e-69ac-4e95-9503-8a4e3bc95e7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clicked load more 1 times, total links so far: 12\n",
      "Clicked load more 2 times, total links so far: 24\n",
      "Clicked load more 3 times, total links so far: 36\n",
      "Clicked load more 4 times, total links so far: 48\n",
      "Clicked load more 5 times, total links so far: 60\n",
      "Clicked load more 6 times, total links so far: 72\n",
      "Clicked load more 7 times, total links so far: 84\n",
      "Clicked load more 8 times, total links so far: 96\n",
      "Clicked load more 9 times, total links so far: 108\n",
      "Clicked load more 10 times, total links so far: 120\n",
      "Clicked load more 11 times, total links so far: 132\n",
      "Clicked load more 12 times, total links so far: 144\n",
      "Clicked load more 13 times, total links so far: 156\n",
      "Clicked load more 14 times, total links so far: 168\n",
      "Clicked load more 15 times, total links so far: 180\n",
      "Clicked load more 16 times, total links so far: 192\n",
      "Clicked load more 17 times, total links so far: 204\n",
      "Clicked load more 18 times, total links so far: 216\n",
      "Clicked load more 19 times, total links so far: 228\n",
      "Clicked load more 20 times, total links so far: 240\n",
      "Clicked load more 21 times, total links so far: 252\n",
      "Clicked load more 22 times, total links so far: 264\n",
      "Clicked load more 23 times, total links so far: 276\n",
      "Clicked load more 24 times, total links so far: 288\n",
      "Clicked load more 25 times, total links so far: 300\n",
      "Clicked load more 26 times, total links so far: 312\n",
      "Clicked load more 27 times, total links so far: 324\n",
      "Clicked load more 28 times, total links so far: 336\n",
      "Clicked load more 29 times, total links so far: 348\n",
      "Clicked load more 30 times, total links so far: 360\n",
      "Clicked load more 31 times, total links so far: 372\n",
      "Clicked load more 32 times, total links so far: 384\n",
      "Clicked load more 33 times, total links so far: 396\n",
      "Clicked load more 34 times, total links so far: 408\n",
      "Clicked load more 35 times, total links so far: 420\n",
      "Clicked load more 36 times, total links so far: 432\n",
      "Clicked load more 37 times, total links so far: 444\n",
      "Clicked load more 38 times, total links so far: 456\n",
      "Clicked load more 39 times, total links so far: 468\n",
      "Clicked load more 40 times, total links so far: 480\n",
      "Clicked load more 41 times, total links so far: 492\n",
      "Clicked load more 42 times, total links so far: 504\n",
      "Clicked load more 43 times, total links so far: 516\n",
      "Clicked load more 44 times, total links so far: 528\n",
      "Clicked load more 45 times, total links so far: 540\n",
      "Clicked load more 46 times, total links so far: 552\n",
      "Clicked load more 47 times, total links so far: 564\n",
      "Clicked load more 48 times, total links so far: 576\n",
      "Clicked load more 49 times, total links so far: 588\n",
      "Clicked load more 50 times, total links so far: 600\n",
      "Clicked load more 51 times, total links so far: 612\n",
      "Clicked load more 52 times, total links so far: 624\n",
      "Clicked load more 53 times, total links so far: 636\n",
      "Clicked load more 54 times, total links so far: 648\n",
      "Clicked load more 55 times, total links so far: 660\n",
      "Clicked load more 56 times, total links so far: 672\n",
      "Clicked load more 57 times, total links so far: 684\n",
      "Clicked load more 58 times, total links so far: 696\n",
      "Clicked load more 59 times, total links so far: 708\n",
      "Clicked load more 60 times, total links so far: 720\n",
      "Clicked load more 61 times, total links so far: 732\n",
      "Clicked load more 62 times, total links so far: 744\n",
      "Clicked load more 63 times, total links so far: 756\n",
      "Clicked load more 64 times, total links so far: 768\n",
      "Clicked load more 65 times, total links so far: 780\n",
      "Clicked load more 66 times, total links so far: 792\n",
      "Clicked load more 67 times, total links so far: 804\n",
      "Clicked load more 68 times, total links so far: 816\n",
      "Clicked load more 69 times, total links so far: 828\n",
      "Clicked load more 70 times, total links so far: 840\n",
      "Clicked load more 71 times, total links so far: 852\n",
      "Clicked load more 72 times, total links so far: 864\n",
      "Clicked load more 73 times, total links so far: 876\n",
      "Clicked load more 74 times, total links so far: 888\n",
      "Clicked load more 75 times, total links so far: 900\n",
      "Clicked load more 76 times, total links so far: 912\n",
      "Clicked load more 77 times, total links so far: 924\n",
      "Clicked load more 78 times, total links so far: 936\n",
      "Clicked load more 79 times, total links so far: 948\n",
      "Clicked load more 80 times, total links so far: 960\n",
      "Clicked load more 81 times, total links so far: 972\n",
      "Clicked load more 82 times, total links so far: 984\n",
      "Clicked load more 83 times, total links so far: 996\n",
      "Clicked load more 84 times, total links so far: 1008\n",
      "Clicked load more 85 times, total links so far: 1020\n",
      "Clicked load more 86 times, total links so far: 1032\n",
      "Clicked load more 87 times, total links so far: 1044\n",
      "Clicked load more 88 times, total links so far: 1056\n",
      "Clicked load more 89 times, total links so far: 1068\n",
      "Clicked load more 90 times, total links so far: 1080\n",
      "Clicked load more 91 times, total links so far: 1092\n",
      "Clicked load more 92 times, total links so far: 1104\n",
      "Clicked load more 93 times, total links so far: 1116\n",
      "Clicked load more 94 times, total links so far: 1128\n",
      "Clicked load more 95 times, total links so far: 1140\n",
      "Clicked load more 96 times, total links so far: 1152\n",
      "Clicked load more 97 times, total links so far: 1164\n",
      "Clicked load more 98 times, total links so far: 1176\n",
      "Clicked load more 99 times, total links so far: 1188\n",
      "Clicked load more 100 times, total links so far: 1200\n",
      "No more button, finished loading all articles.\n",
      "Found 1212 article links\n",
      "ðŸ’¾ Saved 1000 articles to data/voa_burmese_part1.json\n",
      "ðŸ’¾ Saved 212 articles to data/voa_burmese_part2.json\n",
      "âœ… Scraping finished!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Collect all article links (auto-load)\n",
    "# -------------------------------\n",
    "def get_all_links(base_url):\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(base_url)\n",
    "\n",
    "    links = set()\n",
    "    click_count = 0\n",
    "\n",
    "    while True:\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        for a in soup.select(\"a[href*='/a/']\"):\n",
    "            url = a.get(\"href\")\n",
    "            if url and url.startswith(\"/a/\"):\n",
    "                links.add(\"https://burmese.voanews.com\" + url)\n",
    "\n",
    "        try:\n",
    "            button = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.link-showMore\"))\n",
    "            )\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            click_count += 1\n",
    "            print(f\"Clicked load more {click_count} times, total links so far: {len(links)}\")\n",
    "        except:\n",
    "            print(\"No more button, finished loading all articles.\")\n",
    "            break\n",
    "\n",
    "    driver.quit()\n",
    "    return list(links)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Scrape each article with retry\n",
    "# -------------------------------\n",
    "def scrape_article(url, retries=3):\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "            title_el = soup.find(\"h1\")\n",
    "            title = title_el.get_text(strip=True) if title_el else \"\"\n",
    "\n",
    "            paragraphs = []\n",
    "            for selector in [\"div.wsw p\", \"div.content p\", \"div.article__body p\"]:\n",
    "                ps = [p.get_text(strip=True) for p in soup.select(selector)]\n",
    "                paragraphs.extend(ps)\n",
    "\n",
    "            paragraphs = [p for p in paragraphs if p and \"No media source currently available\" not in p]\n",
    "            text = \"\\n\".join(paragraphs)\n",
    "\n",
    "            return {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"title\": title,\n",
    "                \"text\": text,\n",
    "                \"domain\": \"News\",\n",
    "                \"url\": url\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping {url} attempt {attempt+1}: {e}\")\n",
    "            time.sleep(1)\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: Save JSON chunk\n",
    "# -------------------------------\n",
    "def save_chunk(data, chunk_num, output_dir=\"data\"):\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    filename = f\"{output_dir}/voa_burmese_part{chunk_num}.json\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    print(f\"ðŸ’¾ Saved {len(data)} articles to {filename}\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: Run scraper in parallel & auto-split\n",
    "# -------------------------------\n",
    "def scrape_all(base_url, workers=20, chunk_size=1000):\n",
    "    links = get_all_links(base_url)\n",
    "    print(f\"Found {len(links)} article links\")\n",
    "\n",
    "    results = []\n",
    "    chunk_num = 1\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        future_to_url = {executor.submit(scrape_article, url): url for url in links}\n",
    "        for i, future in enumerate(as_completed(future_to_url), 1):\n",
    "            data = future.result()\n",
    "            if data:\n",
    "                results.append(data)\n",
    "\n",
    "            # Save every chunk_size articles\n",
    "            if len(results) >= chunk_size:\n",
    "                save_chunk(results, chunk_num)\n",
    "                chunk_num += 1\n",
    "                results = []\n",
    "\n",
    "    # Save remaining articles\n",
    "    if results:\n",
    "        save_chunk(results, chunk_num)\n",
    "\n",
    "    print(\"âœ… Scraping finished!\")\n",
    "\n",
    "# -------------------------------\n",
    "# RUN\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_all(\"https://burmese.voanews.com/myanmar\", workers=28, chunk_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67565fb8-bd48-4145-9f08-6de17403c8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
